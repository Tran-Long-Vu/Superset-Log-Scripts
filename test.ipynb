{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"json_logs/data_2024-08-10.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         [1723309193651132899, [2024-08-10 23:59:53,650...\n",
      "1         [1723309193637122165, [2024-08-10 23:59:53,636...\n",
      "2         [1723309193636873898, 2024-08-10 23:59:53.636 ...\n",
      "3         [1723309193636641633, 2024-08-10 23:59:53.636 ...\n",
      "4         [1723309193636314748, 2024-08-10 23:59:53.635 ...\n",
      "                                ...                        \n",
      "381385    [1723222801810788423, 2024-08-10 00:00:01.810 ...\n",
      "381386    [1723222801810352895, 2024-08-10 00:00:01.809 ...\n",
      "381387    [1723222801809469360, 2024-08-10 00:00:01.809 ...\n",
      "381388    [1723222801808928470, 2024-08-10 00:00:01.808 ...\n",
      "381389    [1723222801803578603, [2024-08-10 00:00:01,802...\n",
      "Length: 381390, dtype: object\n"
     ]
    }
   ],
   "source": [
    "values = data['data']['result'][0]['values']\n",
    "\n",
    "series_1 = pd.Series(values)\n",
    "\n",
    "print(series_1)\n",
    "# inside json theres another set of data. \n",
    "# formulate to df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381389    [1723222801803578603, [2024-08-10 00:00:01,802...\n",
      "381388    [1723222801808928470, 2024-08-10 00:00:01.808 ...\n",
      "381387    [1723222801809469360, 2024-08-10 00:00:01.809 ...\n",
      "381386    [1723222801810352895, 2024-08-10 00:00:01.809 ...\n",
      "381385    [1723222801810788423, 2024-08-10 00:00:01.810 ...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# reverse: \n",
    "rev_series_1 = series_1.iloc[::-1]\n",
    "print(rev_series_1.head(5))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data point appears 34560 times.\n"
     ]
    }
   ],
   "source": [
    "# The specific data point to count\n",
    "search_string = '========================Start fetch event==========================='\n",
    "\n",
    "# Count occurrences of the search string\n",
    "count = sum('Start fetch event' in value[1] for value in rev_series_1)\n",
    "# Display the coun t\n",
    "print(f\"The data point appears {count} times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data point appears 122 times.\n",
      "381390\n"
     ]
    }
   ],
   "source": [
    "# The specific data point to count\n",
    "search_string = 'Delay alarm event:'\n",
    "\n",
    "# Count occurrences of the search string\n",
    "count = sum(search_string in value[1] for value in rev_series_1)\n",
    "# Display the coun t\n",
    "print(f\"The data point appears {count} times.\")\n",
    "\n",
    "print(str(len(rev_series_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def collect all events\n",
    "collect every data point between 25(start) and 32(end) == event codes: 32,99,120,...\n",
    "gather all that for an event(datapoint)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "def collect_all_events(series):\n",
    "    # Initialize lists to store indices\n",
    "    start_indices = []\n",
    "    end_indices = []\n",
    "\n",
    "    # Iterate through the Series to find all start and end indices\n",
    "    for i, value in enumerate(series):\n",
    "        if 'Start fetch event' in str(value):\n",
    "            start_indices.append(i)  # Capture the start index\n",
    "        elif '======END======' in str(value):\n",
    "            end_indices.append(i)  # Capture the end index\n",
    "\n",
    "    # Gather all segments between each pair of start and end indices\n",
    "    log_segments = []\n",
    "    for start in start_indices:\n",
    "        for end in end_indices:\n",
    "            if end > start:  # Ensure end is after start\n",
    "                # Combine all values between start and end into a single log string\n",
    "                segment = ' '.join(str(series[i]) for i in range(start + 1, end))\n",
    "                log_segments.append(segment)\n",
    "                break  # Move to the next start after finding the first end\n",
    "\n",
    "    # Create a DataFrame with an index column and the combined log string\n",
    "    event_data_df = pd.DataFrame(log_segments, columns=['Log String'])\n",
    "    event_data_df.index.name = 'Index'  # Set the index name\n",
    "\n",
    "    return event_data_df\n",
    "\n",
    "event_data_df = collect_all_events(rev_series_1) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of                                               Log String\n",
      "Index                                                   \n",
      "0      ['1723309193636873898', '2024-08-10 23:59:53.6...\n",
      "1      ['1723309193580237251', '2024-08-10 23:59:53.5...\n",
      "2      ['1723309193519199718', '2024-08-10 23:59:53.5...\n",
      "3      ['1723309193460948961', '2024-08-10 23:59:53.4...\n",
      "4      ['1723309183712591873', '2024-08-10 23:59:43.7...\n",
      "...                                                  ...\n",
      "34555  ['1723222811856529565', '2024-08-10 00:00:11.8...\n",
      "34556  ['1723222802081308447', '2024-08-10 00:00:02.0...\n",
      "34557  ['1723222802015991851', '2024-08-10 00:00:02.0...\n",
      "34558  ['1723222801949848074', '2024-08-10 00:00:01.9...\n",
      "34559  ['1723222801858541692', '2024-08-10 00:00:01.8...\n",
      "\n",
      "[34560 rows x 1 columns]>\n"
     ]
    }
   ],
   "source": [
    "# print(event_data_df)\n",
    "print(event_data_df.describe) # 34650 event, in a log string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Log String\n",
      "Index                                                   \n",
      "0      ['1723309193636873898', '2024-08-10 23:59:53.6...\n",
      "1      ['1723309193580237251', '2024-08-10 23:59:53.5...\n",
      "2      ['1723309193519199718', '2024-08-10 23:59:53.5...\n",
      "3      ['1723309193460948961', '2024-08-10 23:59:53.4...\n",
      "4      ['1723309183712591873', '2024-08-10 23:59:43.7...\n",
      "...                                                  ...\n",
      "34555  ['1723222811856529565', '2024-08-10 00:00:11.8...\n",
      "34556  ['1723222802081308447', '2024-08-10 00:00:02.0...\n",
      "34557  ['1723222802015991851', '2024-08-10 00:00:02.0...\n",
      "34558  ['1723222801949848074', '2024-08-10 00:00:01.9...\n",
      "34559  ['1723222801858541692', '2024-08-10 00:00:01.8...\n",
      "\n",
      "[34560 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "sample_logs = event_data_df\n",
    "print(sample_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index\n",
      "0        ['1723309193636873898', '2024-08-10 23:59:53.6...\n",
      "1        ['1723309193580237251', '2024-08-10 23:59:53.5...\n",
      "2        ['1723309193519199718', '2024-08-10 23:59:53.5...\n",
      "3        ['1723309193460948961', '2024-08-10 23:59:53.4...\n",
      "4        ['1723309183712591873', '2024-08-10 23:59:43.7...\n",
      "                               ...                        \n",
      "34555    ['1723222811856529565', '2024-08-10 00:00:11.8...\n",
      "34556    ['1723222802081308447', '2024-08-10 00:00:02.0...\n",
      "34557    ['1723222802015991851', '2024-08-10 00:00:02.0...\n",
      "34558    ['1723222801949848074', '2024-08-10 00:00:01.9...\n",
      "34559    ['1723222801858541692', '2024-08-10 00:00:01.8...\n",
      "Name: Log String, Length: 34560, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Output the new data points\n",
    "print(sample_logs['Log String'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to extract timestamp\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "\n",
    "# Sample log data\n",
    "data = sample_logs\n",
    "\n",
    "# def find_timestamp(log_string):\n",
    "    \n",
    "#     timestamp_match = re.search(r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\", str(log_string))\n",
    "#     if timestamp_match:\n",
    "#         timestamp = timestamp_match.group(1) # Get the first timestamp\n",
    "#         print(timestamp) # \n",
    "# pass\n",
    "# timestamp = find_timestamp(data)\n",
    "# print(timestamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'[' was never closed (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[106], line 208\u001b[0m\n    ]] = one_day_df['Log String'].apply(extract_fields)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/python3.10/lib/python3.10/site-packages/pandas/core/series.py:4771\u001b[0m in \u001b[1;35mapply\u001b[0m\n    return SeriesApply(self, func, convert_dtype, args, kwargs).apply()\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/python3.10/lib/python3.10/site-packages/pandas/core/apply.py:1123\u001b[0m in \u001b[1;35mapply\u001b[0m\n    return self.apply_standard()\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/python3.10/lib/python3.10/site-packages/pandas/core/apply.py:1174\u001b[0m in \u001b[1;35mapply_standard\u001b[0m\n    mapped = lib.map_infer(\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32mpandas/_libs/lib.pyx:2924\u001b[0m in \u001b[1;35mpandas._libs.lib.map_infer\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[106], line 89\u001b[0m in \u001b[1;35mextract_fields\u001b[0m\n    response_dict = ast.literal_eval(response_str)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/python3.10/lib/python3.10/ast.py:62\u001b[0m in \u001b[1;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string.lstrip(\" \\t\"), mode='eval')\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/anaconda3/envs/python3.10/lib/python3.10/ast.py:50\u001b[0;36m in \u001b[0;35mparse\u001b[0;36m\n\u001b[0;31m    return compile(source, filename, mode, flags,\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<unknown>:1\u001b[0;36m\u001b[0m\n\u001b[0;31m    {'code': 2000, 'msg': 'Success', 'data': {'SerialNumber': 'ba39b3962a4bfe81', 'AlarmTotal': 1, 'AlarmArray': [{'AlarmEvent': 'VideoMotion:2', 'AlarmId': '2481018550', 'AlarmMsg': '', 'AlarmTime': '2024-08-10 18:55:01', 'Channel': '0', 'PicInfo': {'ObjName': '003/003_ba39b3962a4bfe81_2481018550.jpeg', 'ObjSize': 46411, 'StorageBucket': 'OBS_sg-ai-img'}}\u001b[0m\n\u001b[0m                                                                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '[' was never closed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # type: ignore\n",
    "import ast\n",
    "import re\n",
    "\n",
    "# Sample log data\n",
    "# Create a DataFrame\n",
    "one_day_df = sample_logs\n",
    "\n",
    "# Function to extract specific fields from the log messages\n",
    "def extract_fields(log):\n",
    "    # Initialize variables for the fields to extract\n",
    "    \n",
    "    # args\n",
    "    timestamp = ''\n",
    "    sn = ''\n",
    "    user_id = ''\n",
    "    token = ''\n",
    "    time_millis = ''\n",
    "    encrypted_str = ''\n",
    "    time_query_latest = ''\n",
    "    datetime = ''\n",
    "    \n",
    "    # request get event list\n",
    "    request_sn = ''\n",
    "    request_start_time = ''\n",
    "    request_end_time = ''\n",
    "    \n",
    "    # response get event list\n",
    "    response_code = ''\n",
    "    response_msg = ''\n",
    "    \n",
    "    # data\n",
    "    response_sn = ''\n",
    "    alarm_total = ''\n",
    "    alarm_array = []\n",
    "    is_finished = ''\n",
    "    \n",
    "    \n",
    "    # alarm\n",
    "    alarm_event = ''\n",
    "    alarm_id = ''\n",
    "    alarm_msg = ''\n",
    "    alarm_time = ''\n",
    "    alarm_auth_code = ''\n",
    "    alarm_channel = ''\n",
    "    alarm_serial_number = ''\n",
    "    alarm_status = ''\n",
    " \n",
    "    timestamp_match = re.search(r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\", str(log))\n",
    "    if timestamp_match:\n",
    "        timestamp = timestamp_match.group(1) # Get the first timestamp\n",
    "        # print(timestamp) #     \n",
    "    # Check if the log contains 'arg: {'\n",
    "    if 'arg: {' in log:\n",
    "        arg_match = re.search(r'arg: (.*?)}', log)\n",
    "        if arg_match:\n",
    "            args = arg_match.group(1) + '}'\n",
    "            \n",
    "            args_dict = ast.literal_eval(args)\n",
    "            sn = args_dict.get('sn', '')\n",
    "            user_id = args_dict.get('user_id', '')\n",
    "            token = args_dict.get('token', '')\n",
    "            time_millis = args_dict.get('time_millis', '')\n",
    "            encrypted_str = args_dict.get('encrypted_str', '')\n",
    "            time_query_latest = args_dict.get('time_query_latest', '')\n",
    "            datetime = args_dict.get('datetime','')            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    # Check if the log contains 'Request get event list'\n",
    "    if 'Request get event list' in log:\n",
    "        request_match = re.search(r'Request get event list: (.*?)}', log)\n",
    "        if request_match:\n",
    "            request_args = request_match.group(1) + '}'\n",
    "            request_dict = ast.literal_eval(request_args)\n",
    "            request_sn = request_dict.get('sn', '')\n",
    "            request_start_time = request_dict.get('startTime', '')\n",
    "            request_end_time = request_dict.get('endTime', '')\n",
    "            \n",
    "        #except (SyntaxError, ValueError):\n",
    "        #    pass\n",
    "\n",
    "    # Check if the log contains 'Response get event list'\n",
    "    if 'Response get event list' in log:\n",
    "        response_match = re.search(r\"Response get event list: (.*?)}\", log)\n",
    "        if response_match:\n",
    "            response_str = response_match.group(1) + '}}'\n",
    "            response_dict = ast.literal_eval(response_str)\n",
    "            \n",
    "            response_code = response_dict.get('code', '')\n",
    "            response_msg = response_dict.get('msg', '')\n",
    "    if \"'data': {\" in log:\n",
    "        data_match = re.search(r\"'data': (.*?)}\", log)\n",
    "        data_str = data_match.group(1) + '}'\n",
    "        data_dict = ast.literal_eval(data_str)\n",
    "        \n",
    "        response_sn = data_dict.get('SerialNumber','')\n",
    "        alarm_total = data_dict.get('AlarmTotal','')\n",
    "        print( 'total ' +  alarm_total)\n",
    "        if alarm_total is not '0': # response found alarm.\n",
    "            if \"'AlarmArray': [{\" in log:\n",
    "                alarm_array_match = re.search(r\"'AlarmArray': (.*?) }]\", log)\n",
    "                alarm_array_str = alarm_array_match.group(1) + '}]'\n",
    "                alarm_array_dict = ast.literal_eval(data_str)\n",
    "                # alarm_match = re.search(r\"Request': (.*?)}\", log)\n",
    "                # alarm_str = alarm_match.group(1) + '}'\n",
    "                # alarm_dict = ast.literal_eval(alarm_str)\n",
    "                \n",
    "                # alarm_event = alarm_dict.get('alarm_event','')\n",
    "                # alarm_id = alarm_dict.get('alarm_id','')\n",
    "                # alarm_msg = alarm_dict.get('alarm_msg','')\n",
    "                # alarm_time = alarm_dict.get('alarm_time','')\n",
    "                # alarm_auth_code = alarm_dict.get('auth_code','')\n",
    "                # alarm_channel = alarm_dict.get('channel','')\n",
    "                # alarm_serial_number = alarm_dict.get('serial_number','')\n",
    "                # alarm_status = alarm_dict.get('status','')\n",
    "                # print(  'alarm time: '  +  alarm_time)\n",
    "                pass\n",
    "        else:\n",
    "            alarm_array = data_dict.get('AlarmArray','')\n",
    "        is_finished = data_dict.get('IsFinished','')\n",
    "        # print( ' response ' + response_sn)\n",
    "    \n",
    "    # delay alarm event \n",
    "    # \n",
    "    # NOTE: delay alarm event is not {} JSON\n",
    "    \n",
    "    \n",
    "    # if \"Delay alarm event: \" in log:\n",
    "    #     delay_alarm_match = re.search(r\"Delay alarm event: (.*?)\", log)\n",
    "    #     delay_alarm_str = delay_alarm_match.group(1) + '}'\n",
    "    #     delay_alarm_dict = ast.literal_eval(data_str)\n",
    "    \n",
    "    #     delay_alarm_time = delay_alarm_dict.get('')\n",
    "    \n",
    "    # Alarm request\n",
    "    \n",
    "    if \"Request': {\" in log:\n",
    "        alarm_match = re.search(r\"Request': (.*?)}\", log)\n",
    "        alarm_str = alarm_match.group(1) + '}'\n",
    "        alarm_dict = ast.literal_eval(alarm_str)\n",
    "        \n",
    "        alarm_event = alarm_dict.get('alarm_event','')\n",
    "        alarm_id = alarm_dict.get('alarm_id','')\n",
    "        alarm_msg = alarm_dict.get('alarm_msg','')\n",
    "        alarm_time = alarm_dict.get('alarm_time','')\n",
    "        alarm_auth_code = alarm_dict.get('auth_code','')\n",
    "        alarm_channel = alarm_dict.get('channel','')\n",
    "        alarm_serial_number = alarm_dict.get('serial_number','')\n",
    "        alarm_status = alarm_dict.get('status','')\n",
    "        # print(  'alarm time: '  +  alarm_time)\n",
    "    # if alarmArray is True:\n",
    "    \n",
    "    \n",
    "    \n",
    "    return pd.Series([  # args (total 24 columns)\n",
    "                        timestamp,\n",
    "                        sn,\n",
    "                        user_id, \n",
    "                        token, \n",
    "                        time_millis, \n",
    "                        encrypted_str, \n",
    "                        time_query_latest, \n",
    "                        datetime,\n",
    "                        request_start_time,\n",
    "                        request_end_time, \n",
    "                        response_code, \n",
    "                        response_msg,\n",
    "                        # request \n",
    "                        request_sn ,\n",
    "                        request_start_time,\n",
    "                        request_end_time ,\n",
    "                        # response\n",
    "                        response_code ,\n",
    "                        response_msg,\n",
    "                        # data (response)\n",
    "                        response_sn,\n",
    "                        alarm_total,\n",
    "                        alarm_array,\n",
    "                        is_finished,\n",
    "                        #alarm\n",
    "                        alarm_event,\n",
    "                        alarm_id,\n",
    "                        alarm_msg,\n",
    "                        alarm_time,\n",
    "                        alarm_auth_code,\n",
    "                        alarm_channel,\n",
    "                        alarm_serial_number,\n",
    "                        alarm_status,                      \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        ])\n",
    "    \n",
    "# Apply the extraction function to the DataFrame\n",
    "df[[# args\n",
    "    'Timestamp',\n",
    "    'SN', \n",
    "    'UserID',\n",
    "    'Token',\n",
    "    'TimeMillis',\n",
    "    'EncryptedStr',\n",
    "    'TimeQueryLatest',\n",
    "    'DateTime',\n",
    "    'StartTime',\n",
    "    'EndTime',\n",
    "    'ResponseCode',\n",
    "    'ResponseMsg',\n",
    "    # request \n",
    "    'RequestSN' ,\n",
    "    'RequestStartTime',\n",
    "    'RequestEndTime' ,\n",
    "    # response\n",
    "    'ResponseCode' ,\n",
    "    'ResponseMsg',\n",
    "    # data (response)\n",
    "    'ResponseSN',\n",
    "    'AlarmTotal',\n",
    "    'AlarmArray',# in case of nested alarm json.\n",
    "    'IsFinished',\n",
    "    #alarm\n",
    "    'AlarmEvent',\n",
    "    'AlarmId',\n",
    "    'AlarmMsg',\n",
    "    'AlarmTime',\n",
    "    'AlarmAuthCode',\n",
    "    'AlarmChannel',\n",
    "    'AlarmSerialNumber',\n",
    "    'AlarmStatus',      \n",
    "    \n",
    "    ]] = one_day_df['Log String'].apply(extract_fields) \n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print( df [[# args\n",
    "    'Timestamp',\n",
    "    'SN', \n",
    "    'UserID',\n",
    "    'Token',\n",
    "    'TimeMillis',\n",
    "    'EncryptedStr',\n",
    "    'TimeQueryLatest',\n",
    "    'StartTime',\n",
    "    'EndTime',\n",
    "    'ResponseCode',\n",
    "    'ResponseMsg',\n",
    "    # request \n",
    "    'RequestSN' ,\n",
    "    'RequestStartTime',\n",
    "    'RequestEndTime' ,\n",
    "    # response\n",
    "    'ResponseCode' ,\n",
    "    'ResponseMsg',\n",
    "    # data (response)\n",
    "    'ResponseSN',\n",
    "    'AlarmTotal',\n",
    "    'AlarmArray',\n",
    "    'IsFinished',\n",
    "    #alarm\n",
    "    'AlarmEvent',\n",
    "    'AlarmId',\n",
    "    'AlarmMsg',\n",
    "    'AlarmTime',\n",
    "    'AlarmAuthCode',\n",
    "    'AlarmChannel',\n",
    "    'AlarmSerialNumber',\n",
    "    'AlarmStatus',   \n",
    "       \n",
    "    \n",
    "    ]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df = df\n",
    "csv_df = csv_df.drop(columns=['Log String'])\n",
    "csv_df\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_df.to_csv('extracted_log_data.csv', index=False)\n",
    "\n",
    "# # Display a message indicating the file has been saved\n",
    "# print(\"DataFrame has been saved to 'extracted_log_data.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-10 00:00:11\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json data npormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nForm tabular Dataframe\\n\\n\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "'''\n",
    "Form tabular Dataframe\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplot data\\n\\n\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "plot data\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
